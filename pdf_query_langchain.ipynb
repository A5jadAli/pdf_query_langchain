{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **PDFQuery with LangChain**"
      ],
      "metadata": {
        "id": "Wr2f-Of5hWO2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWoR_M1LhNq3"
      },
      "outputs": [],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## langchain componenets to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "yzmo5ecAhxyu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## support for dataset retrieval with HuggingFace\n",
        "from datasets import load_dataset\n",
        "\n",
        "# with CassioIO, the engine powering the Astra DB integration in Langchain,\n",
        "# you will also initialize the DB connection\n",
        "import cassio"
      ],
      "metadata": {
        "id": "FqFHR_-gia_a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MMJj3sJi-tW",
        "outputId": "5440a526-c123-47bb-e408-7e62bd340f77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/232.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "OerxSszgjK9u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:DPAoLxBRoFvZNenJFqWLNaTG:d340660d2361cc9f1a77ffb6a1f0fcf9a2e39c6bd225ec6b05503c63a11cb51b\"\n",
        "ASTRA_DB_ID = \"815af808-94fb-4aa0-9d90-feee14e101dc\"\n",
        "\n",
        "OPENAI_API_KEY = \"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\""
      ],
      "metadata": {
        "id": "7gG3sntHjezx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader = PdfReader(\"/content/visualizing-data-usingt-sne.pdf\")"
      ],
      "metadata": {
        "id": "AA_Ph3JblFDf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "  content = page.extract_text()\n",
        "  if content:\n",
        "    raw_text += content"
      ],
      "metadata": {
        "id": "QiUce3Hcleja"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Intialize the conncetion to your DB***"
      ],
      "metadata": {
        "id": "w72fhDlpmWDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i3Fle5amioX",
        "outputId": "6ba344b0-9231-404b-b578-e44d31ad4799"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 815af808-94fb-4aa0-9d90-feee14e101dc-us-east1.db.astra.datastax.com:29042:f11c31a5-6872-4929-bed1-14fd72ff5fe1. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 815af808-94fb-4aa0-9d90-feee14e101dc-us-east1.db.astra.datastax.com:29042:f11c31a5-6872-4929-bed1-14fd72ff5fe1. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(134974905360704) 815af808-94fb-4aa0-9d90-feee14e101dc-us-east1.db.astra.datastax.com:29042:f11c31a5-6872-4929-bed1-14fd72ff5fe1> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 815af808-94fb-4aa0-9d90-feee14e101dc-us-east1.db.astra.datastax.com:29042:f11c31a5-6872-4929-bed1-14fd72ff5fe1. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the LangChain embeddings LLM objcets"
      ],
      "metadata": {
        "id": "mlE31NEcnDxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "XFyD102AnGwI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create your LangChain vector store, backed by Astra DB"
      ],
      "metadata": {
        "id": "v7O3HZ0In19z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None\n",
        ")"
      ],
      "metadata": {
        "id": "e0GNsVIZnxmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# we need to split the text using Character Text Split such that it should not increase token size\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "L_AVWiFNok1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to see thet text\n",
        "texts[:30]"
      ],
      "metadata": {
        "id": "M-BHU9K3pZYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset into the vector store"
      ],
      "metadata": {
        "id": "eeKpKBcwppX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store.add_texts(texts[:30])\n",
        "\n",
        "print(len(texts[:30]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "id": "qG68zGZWp1hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the QA Cycle"
      ],
      "metadata": {
        "id": "zF6Q3Rg8qc89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_question = True\n",
        "while True:\n",
        "  if first_question:\n",
        "    query_text = input(\"\\nEnter your question (or type quit to exit): \").strip()\n",
        "  else:\n",
        "    query_text = input(\"\\nEnter your next question (or type quit to exit): \").strip()\n",
        "\n",
        "  if query_text.lower() = \"quit\":\n",
        "    break\n",
        "\n",
        "  if query_text == \"\":\n",
        "    continue\n",
        "\n",
        "  first_question = False\n",
        "\n",
        "  print(\"\\nQuestion: \\%s\\\"\" % query_text)\n",
        "  answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "  print(\"Answer: \\%s\\\"\\n\" % answer)\n",
        "\n",
        "  print(\"First documents by Relevance:\")\n",
        "  for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "    print(\"---[%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:100]))"
      ],
      "metadata": {
        "id": "IHytt7HUqnS7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}